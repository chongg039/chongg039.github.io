<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Knowledge on Co1driver 的个人博客</title>
    <link>https://chongg039.cn/tags/knowledge/</link>
    <description>Recent content in Knowledge on Co1driver 的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright 2014-{year}</copyright>
    <lastBuildDate>Thu, 20 Feb 2020 20:32:59 +0800</lastBuildDate><atom:link href="https://chongg039.cn/tags/knowledge/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[基础知识]计算机网络</title>
      <link>https://chongg039.cn/post/network-base/</link>
      <pubDate>Thu, 20 Feb 2020 20:32:59 +0800</pubDate>
      
      <guid>https://chongg039.cn/post/network-base/</guid>
      <description>TCP拥塞控制：慢开始、拥塞避免、快重传、快恢复 建议阅读博客。
并发和线程 线程数是不是越大越好？ 肯定不是的，首先服务器的cpu核数有限，同时并发的线程数是有限的，1核cpu设置10000个工作线程是没有意义的；线程的切换是有开销的，如果线程切换过于频繁，反而使性能降低。
调用sleep()函数的时候，线程是否一直占用cpu？ 不占用，等待时会把cpu让出来，给其他需要cpu资源的线程使用，不止sleep()函数，在进行一些阻塞调用，例如网络编程中的阻塞accept()【等待客户端连接】和阻塞recv()【等待下游回包】也不占用cpu资源。
补充：sleep与wait方法的区别可以参见之前的一篇博客的介绍：http://blog.csdn.net/megustas_jjc/article/details/71304979
如果cpu是单核的，设置多线程有什么意义，能提高并发性能么？ 即使是单核，使用多线程也是有意义的
 多线程编码可以让我们的服务/代码更加清晰，有些IO线程收发包，有些Worker线程进行任务处理，有些Timeout线程进行超时检测 如果有一个任务一直占用CPU资源在进行计算，那么此时增加线程并不能增加并发，例如这样的一个代码while(1){ i++; }该代码一直不停的占用CPU资源进行计算，会使CPU占用率达到100% 通常来说，Worker线程一般不会一直占用CPU进行计算，此时即使CPU是单核，增加Worker线程也能够提高并发，因为这个线程在休息的时候，其他的线程可以继续工作  TCP序列号和确认号 TCP首部固定长度20字节，可选40字节，即最长60字节。
序列号占32位，即4字节，用来保证交付到的报文的顺序组合，因为可能不是顺序到达的。序号字段只有在下面两种情况的任意一种才有意义：
 数据字段至少包含一个字节 这是一个 SYN 段，或者是 FIN 段，或者是 RST 段。  每传送一个 TCP 段，都要等待对方回复一个确认。不过这种方式效率太低，在 TCP 协议中，一般采用累积确认的方式，即每传送多个连续 TCP 段，可以只对最后一个 TCP 段进行确认。
对方通过回复一个确认号，来表示确认已经接收到了哪个 TCP 段。比如发送方发送了一个报文段序号为 301 的 TCP 段，这个段携带了 100 字节数据，则接收方应当回复的确认号是 401，它表示接收方已经收到了字节序号为 [0, 400] 的数据，现在期望你发送字节序号为 401 以及以后的数据。
保障udp可靠性 UDP不属于连接协议，具有资源消耗少，处理速度快的优点，所以通常音频，视频和普通数据在传送时，使用UDP较多，因为即使丢失少量的包，也不会对接受结果产生较大的影响。
传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。
最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。
 添加seq/ack机制，确保数据发送到对端 添加发送和接收缓冲区，主要是用户超时重传。 添加超时重传机制。  详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。</description>
    </item>
    
    <item>
      <title>[基础知识]操作系统</title>
      <link>https://chongg039.cn/post/os-base/</link>
      <pubDate>Thu, 20 Feb 2020 20:32:11 +0800</pubDate>
      
      <guid>https://chongg039.cn/post/os-base/</guid>
      <description>回顾和整理操作系统相关的知识点以及C++实现。
用户态与内核态 用户态与内核态是Linux的体系结构，也叫用户空间和内核空间，用户态是提供应用程序运行的空间，内核态就是控制计算机硬件运行的那部分特殊的软件运行的空间。用户态的程序想要访问这些硬件资源，内核态必须为之提供一组访问接口，这些接口就被称为系统调用(System Call)。
一般来讲，软件运行在用户态。但当程序需要调用操作系统提供的某一服务，如打开文件、连接设备、fork进程等，就需要切换至内核态，此时进程也就不进行相应的工作了，取而代之的是内核在进行某些处理。
中断是计算机在执行程序时，出现某些特殊的情况导致CPU暂停对指令的执行，转而去处理这项特殊的事务，处理完之后再回去处理先前的任务。中断一般有三类：
 由硬件异常或故障引起的内部异常中断； 由程序中的中断指令引起的软中断； 由外部设备请求引起的外部中断。  我们最为关心的是软中断。当一个进程发出一个系统调用的请求之后，会产生一个软中断，此时系统会对这个软中断进行处理，这样便从用户态切换到了内核态。理论上，这三种中断均可以从用户态切换到内核态。
进程、线程和协程 进程(process)是资源分配的基本单位，一般由代码块、数据区、堆、栈段组成。线程(thread)是CPU调度的基本单位，是进程的一个实体，可独立运行。一个进程一般由多个线程构成，且多个线程可以并发执行。
在同一个进程中，多个线程共享该进程的代码段（代码、常量）、数据段（全局变量、静态变量）和扩展段（堆存储），但拥有各自的栈段，用来存放所有的局部变量和临时变量、程序计数器、线程id和寄存器组中的值。
协程(coroutine)是一种轻量级的用户态的线程，与线程的特点基本一样，但避免了无意义的调度和内核切换的开销，但同时带来的是编写者需要自己承担调度协程的责任，且只能模拟多任务并发，无法使用多核CPU进行并行操作。
PCB与进程的创建 进程控制块(Process Control Block, PCB)是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB中记录了操作系统所需要的、用于描述进程情况及控制进程运行所需要的全部信息。主要包含以下四个部分：
 唯一标识一个进程的进程标识符，有外部标识符和内部标识符； 处理机状态信息； 进程调度信息； 进程控制信息。  系统按照以下流程创建进程：
 分配、初始化PCB； 初始化机器寄存器； 拷贝、初始化内存页表； 从硬盘加载程序代码到内存； 将进程添加至就绪队列； 进程调度时，选择该进程，切换至用户态开始执行该进程。  进程调度算法 操作系统通过进程调度算法快速切换进程，使得每个进程都有一定的时间片来响应用户提交的请求，基本的调度算法有：
FCFS先来先服务 简单，效率低，对长作业有利，对短作业不利；在CPU繁忙型作业上表现可以，不适用于IO繁忙型。
时间片轮转 还是先来先服务，但是每个进程只能运行一个预设的时间片，一个时间片内未完，该进程就必须被剥夺，释放处理器给下一个就绪的进程，并返回就绪队列的末尾等待下一次被调度。因此时间片的选取至关重要，过大退化为FCFS，过小则会频繁切换进程，增大处理器的时间开销导致真正服务于进程的时间变少。
SJF短作业优先 优先调度短作业，长作业可能会产生”饥饿“现象，同时也没有考虑到作业的紧迫程度。
优先级调度 分为剥夺式与非剥夺式：
 非剥夺式优先级调度指当某个进程正在CPU上运行时，有某个更为重要的进程进入了就绪队列，仍让当前进程继续运行，直到其由于自身原因让出处理器，再将处理器分配给更重要的那个进程； 剥夺式优先级调度是指当某个更为重要的进程进入就绪队列时，立即暂停正在运行的进程，将处理器分配给更重要的这个。  多级反馈队列(带优先级的时间片轮转) 算法思想：
 设置多个就绪队列，每个具有不同的优先级，第1级优先级最高，依次降低； 优先级越高的队列中时间片越短，不同就绪队列中时间片依次递增； 每个就绪队列中按照FCFS进行调度； 每次进来一个新的进程，放入第一级就绪队列，并等待调度； 若被调度的进程能够在时间片内执行完，就可从系统中撤离；若没有执行完，将其转入下一级就绪队列的末尾，排队等待调度； 当进程被转入最后一级优先级队列，按照时间片轮转进行调度； 调度程序从高优先级的就绪队列中开始调度，当且仅当该队列为空才从下一级队列开始调度； 若处理器正在执行某进程，又有新的进程添加到了优先级更高的就绪队列中，则立即抢占处理器，将正在执行的进程放入当前就绪队列的末尾，并将处理器分配给更高优先级的进程。  同步与通信 线程之间共享资源，但拥有各自不同的运行栈，进程之间互相隔离。线程并发需要解决的是同步问题，进程则需要解决通信问题。
线程同步 原子操作可以是一个步骤，也可以是按照某个顺序的多个步骤，但是不能被切割，具有整体性。一旦开始就必须执行到结束，中间不能被线程调度机制打断。原子操作是不需要同步的，需要线程同步的根本原因在于对普通变量的操作不是原子的。
涉及原子操作的关键字：synchronize、volatile、atomic。
每个进程中访问临界资源的那部分代码被称为临界区，是每次仅允许一个进程访问的共享资源。互斥访问临界资源一般可以通过信号量(semaphore)或互斥锁(mutex)进行。临界资源数量为1时信号量将退化为锁。
进程通信IPC 管道一般有无名管道和命名管道FIFO。无名管道是unix中IPC最古老的形式，一般由一个读文件描述符fd[0]和写文件描述符fd[1]组成，半双工，只能用于父子进程、兄弟进程之间的通信，是一种存在与内存中的特殊的文件系统。FIFO可以在无关进程之间交换数据，管道中先进先出，是一种文件类型，有路径名。</description>
    </item>
    
    <item>
      <title>[基础知识]C&#43;&#43;基础知识汇总</title>
      <link>https://chongg039.cn/post/cxx-base/</link>
      <pubDate>Sun, 20 Oct 2019 15:51:31 +0800</pubDate>
      
      <guid>https://chongg039.cn/post/cxx-base/</guid>
      <description>指针和引用 联系 C++底层中引用是通过指针实现的，在实现层面上引用就是指针，指向同一对象的内存地址。
所有对引用的操作就是对原始对象的操作。
区别  引用只是别名，不是实体类型，因此编译器不为引用分配单独的内存空间，而指针有自己的内存空间，因此某种程度上指针不能被引用取代； 引用必须被初始化且不能为空，但可以有未初始化的空指针； 引用一旦初始化就不能更换目标，即不能被初始化多次，指针可以更改指向的对象； 可以有指针数组，不能有引用数组，因为引用没有被分配内存； 当引用作为函数的形参时，因为函数形参和实参是同一个对象，避免了复制对象的开销； 若对引用型参数做const修饰，则不会调用拷贝构造函数，提高效率； 若引用作为函数的返回结果，需要保证函数返回后被引用的目标一直有效，即不能返回函数内部的局部对象的引用（因为离开作用域后会被析构掉）。  数组和指针 C++不记录数组本身的大小，因此一定注意不要越界访问。
数组作为形参传递时会退化为同类型的指针：
int data[] = {1, 2, 3, 4, 5}; int size1 = sizeof(data); // 20 int *data2 = data; int size2 = sizeof(data2); // 4  int GetSize(int data[]) { return sizeof(data); } int size3 = GetSize(data); // 4 sizeof使用与陷阱 https://www.cnblogs.com/chio/archive/2007/06/11/778934.html
内存对齐 尽管计算机中内存是按照字节byte划分的，但不是寻址可以从任意的byte开始。一般来说计算机会对基本数据类型数据在内存中存放的位置加以限制，要求首地址必须是某个数（一般是4和8）的倍数，这就是内存对齐。
因为虽然计算机按照字节划分存储空间，但处理器存取一次内存不是按照一个字节存取的，一般以双字节、4字节、8字节甚至到32字节存取。这被称为内存存取粒度。
对32位处理器的int类型（4字节），若数据现在可以存放在任一字节开始处，会产生性能的损失。比如，现在从地址1字节开始存放int（1-5，左开右闭），读取时从0字节开始读取一个4字节大小的块，需要访问两次内存。第一步先读取0-4左开右闭字节快，剔除0地址字节；第二步访问4-8左开右闭字节快，剔除5、6、7三个字节块。然后将这两部分得到的合并放入寄存器，需要做很多工作。有了内存对齐，那么只能从规定的边界存放和读取，访问一次内存就可以了。
设置编译器的”对齐系数(对齐模数)“的预处理指令为#pragma pack(n)，一般32位系统下对齐系数为n=4，64位系统下对齐系数为n=8。还有一个概念为”对齐单位“，也称有效对齐值，是指n和结构体中最长数据类型（基本数据类型）长度中较小的那一个值。
下面说一下内存对齐规则，主要有两条：
 结构体中第一个成员的offset为0，之后每个成员都相对首地址的offset都是”该成员大小“和”对齐单位“中较小的那个的整数倍。如有需要可以添加进填充字节； 结构体的总大小为”对齐单位“的整数倍，如有需要会在最末尾成员添加填充字节。  分析下下面三个例子：
#pragma pack(4) // 先使用第一条规则 // 对x, 对齐单位min(4, 4) = 4, 按照4字节对齐, 不用偏移, 从0开始占用4个字节 // 对c1, 对齐单位min(4, 1) = 1, 按照1字节对齐, 相对于首地址偏移min(1, 1) = 1的倍数, 从4开始占用1个字节 // 对c2, 对齐单位min(4, 1) = 1, 按照1字节对齐, 相对于首地址偏移min(1, 1) = 1的倍数, 从5开始占用1个字节 // 再使用第二条规则, 结构体大小需要是对齐单位的整数倍, 补2个字节在末尾 // sizeof(x1) = 8 typedef struct x1 { int x; char c1; char c2; } x1; // 先使用第一条规则 // 对c1, 对齐单位min(4, 1) = 1, 按照1字节对齐, 不用偏移, 从0开始占用1个字节 // 对c2, 对齐单位min(4, 1) = 1, 按照1字节对齐, 相对于首地址偏移min(1, 1) = 1的倍数, 从1开始占用1个字节 // 对x, 对齐单位min(4, 4) = 4, 按照4字节对齐, 相对于首地址偏移min(4, 4) = 4的倍数, 需要先填充2位, 再从4开始占用4个字节 // 再使用第二条规则, 结构体大小需要是对齐单位的整数倍, 不用补填充字节 // sizeof(x2) = 8 typedef struct x2 { char c1; char c2; int x; } x2; // 先使用第一条规则 // 对c1, 对齐单位min(4, 1) = 1, 按照1字节对齐, 不用偏移, 从0开始占用1个字节 // 对x, 对齐单位min(4, 4) = 4, 按照4字节对齐, 相对于首地址偏移min(4, 4) = 1的倍数, 需要先填充3位, 再从4开始占用4个字节 // 对c2, 对齐单位min(4, 1) = 1, 按照1字节对齐, 相对于首地址偏移min(1, 1) = 1的倍数, 从8开始占用1个字节 // 再使用第二条规则, 结构体大小需要是对齐单位的整数倍, 补3个字节在末尾 // sizeof(x3) = 12 typedef struct x3 { char c1; int x; char c2; } x3; #pragma pack() 准确地讲这是属于内存的字节对齐。还有一个问题是大端对齐和小端对齐，这和处理器的架构有关系。大端对齐模式就是数据的低位保存在内存的高地址，内存的低地址存放着数据的高位。小端对齐模式就是数据的低位保存在内存的低地址中，而数据的高位保存在内存的高地址中。一般都是使用小端对齐的方式，大端对齐主要用在一些大型机的处理器中。</description>
    </item>
    
  </channel>
</rss>
